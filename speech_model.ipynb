{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import shutil\n",
    "import librosa\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data(lang):\n",
    "#     data = pd.read_csv(\"svarah\\/svarah\\/meta_speaker_stats.csv\")\n",
    "    \n",
    "#     text_path = os.path.join(lang+\"_text_files\")\n",
    "#     speech_path = os.path.join(lang+\"_speech_files\")\n",
    "    \n",
    "#     os.makedirs(text_path, exist_ok=True)\n",
    "#     os.makedirs(speech_path, exist_ok=True)\n",
    "    \n",
    "#     data = data[data[\"primary_language\"] == lang]\n",
    "    \n",
    "#     for i,row in data.iterrows():\n",
    "#         if os.path.exists(\"svarah\\svarah/\"+row[0]):\n",
    "#             dest=os.path.join(speech_path,os.path.basename(row[0]))\n",
    "#             shutil.move(\"svarah\\svarah/\"+row[0],dest)\n",
    "        \n",
    "#         if os.path.exists(\"svarah\\svarah/\"+row[0][:-3]+\"txt\"):\n",
    "#             dest=os.path.join(text_path,os.path.basename(row[0][:-3]+\"txt\"))\n",
    "#             shutil.move(\"svarah\\svarah/\"+row[0][:-3]+\"txt\",dest)\n",
    "#     return data\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_data(\"Punjabi\")\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_dir = \"Punjabi_speech_files\"\n",
    "# # transcript_dir = \"Punjabi_speech_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataf = []\n",
    "\n",
    "# for file in os.listdir(\"Punjabi_text_files\"):\n",
    "#     path = os.path.join(\"Punjabi_text_files\",file)\n",
    "#     t_df = pd.read_csv(path, encoding=\"utf-8\", sep='\\s+', header=None)\n",
    "#     if t_df.shape[1] > 3:\n",
    "#             tt_df = t_df.iloc[:, :3] \n",
    "#             additional_columns = t_df.iloc[:, 3:].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "#             tt_df[2] = additional_columns \n",
    "#     dataf.append(tt_df)\n",
    "    \n",
    "# combined_df = pd.concat(dataf, ignore_index=True)\n",
    "# # combined_df.columns = ['file', 'number', 'transcript']\n",
    "# combined_df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_data = []\n",
    "# for i,row in combined_df.iterrows():\n",
    "#     audio_path = os.path.join(\"Punjabi_speech_files\",os.path.basename(row[0]))\n",
    "    \n",
    "#     y,sr = librosa.load(audio_path, sr = None)\n",
    "#     audio_data.append((y,sr,row[2]))\n",
    "\n",
    "# print(len(audio_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_df = pd.DataFrame(audio_data)\n",
    "# audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list=[]\n",
    "\n",
    "# for i in audio_data:\n",
    "#     y,sr=i[0],i[1]\n",
    "#     mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "#     zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "#     spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    \n",
    "#     mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "#     features = {\n",
    "#         'mel_spectrogram': mel_spectrogram_db.mean(axis=1),  # mean over time\n",
    "#         'mfcc': mfcc.mean(axis=1),\n",
    "#         'zero_crossing_rate': zero_crossing_rate.mean(),\n",
    "#         'spectral_centroid': spectral_centroid.mean()\n",
    "#     }\n",
    "    \n",
    "#     features_list.append(features)\n",
    "\n",
    "# train_data_frame = pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_data(df):\n",
    "#     # Check for missing values\n",
    "#     if df.isnull().values.any():\n",
    "#         print(\"Missing values found. Filling with mean for numeric columns.\")\n",
    "#         numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())  # Fill missing values for numeric columns\n",
    "\n",
    "#     # Select numeric columns for scaling\n",
    "#     numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "#     # Check if we have any numeric columns\n",
    "#     if numeric_df.empty:\n",
    "#         raise ValueError(\"No numeric columns to scale.\")\n",
    "\n",
    "#     # Scaling the features\n",
    "#     scaler = StandardScaler()\n",
    "    \n",
    "#     try:\n",
    "#         # Fit and transform the numeric data\n",
    "#         scaled_features = scaler.fit_transform(numeric_df)\n",
    "\n",
    "#         # Create a DataFrame with scaled features\n",
    "#         scaled_df = pd.DataFrame(scaled_features, columns=numeric_df.columns)\n",
    "\n",
    "#         # Concatenate scaled features with non-numeric features\n",
    "#         non_numeric_df = df.select_dtypes(exclude=['float64', 'int64'])\n",
    "#         full_df = pd.concat([scaled_df, non_numeric_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#         # Splitting the data into train, validation, and test sets (80% train, 10% validation, 10% test)\n",
    "#         X_train, X_temp = train_test_split(full_df, test_size=0.2, random_state=42)\n",
    "#         X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#         return X_train, X_val, X_test\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error while scaling: {e}\")\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_val,X_Test = preprocess_data(train_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_punjabi_data(df):\n",
    "#     # Check for missing values in the DataFrame\n",
    "#     if df.isnull().values.any():\n",
    "#         print(\"Missing values found. Filling with empty string for text columns.\")\n",
    "#         df.fillna({'transcript': ''}, inplace=True)  # Fill missing transcripts with an empty string\n",
    "\n",
    "#     # Ensure the paths to audio files exist\n",
    "#     df['audio_exists'] = df['audio_file'].apply(os.path.exists)\n",
    "\n",
    "#     # Filter out any rows where the audio file does not exist\n",
    "#     df = df[df['audio_exists']]\n",
    "\n",
    "#     # Optional: Perform additional cleaning on transcripts (e.g., removing special characters)\n",
    "#     df['transcript'] = df['transcript'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "#     # Prepare data for model training\n",
    "#     # Here, we could convert transcripts to a suitable format, e.g., phonemes or embeddings,\n",
    "#     # but for simplicity, we'll keep them as is.\n",
    "\n",
    "#     # Splitting the data into train, validation, and test sets (80% train, 10% validation, 10% test)\n",
    "#     train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "#     val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "#     return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcript_data(entry):\n",
    "    # Flatten the JSON structure\n",
    "    records = []\n",
    "    \n",
    "    # Extracting metadata\n",
    "    language = entry.get(\"language\", \"\")\n",
    "    audio_duration = entry.get(\"audio_raw_duration\", 0)\n",
    "    scenario = entry.get(\"scenario\", \"\")\n",
    "    task_name = entry.get(\"task_name\", \"\")\n",
    "    gender = entry.get(\"gender\", \"\")\n",
    "    age_group = entry.get(\"age_group\", \"\")\n",
    "    job_type = entry.get(\"job_type\", \"\")\n",
    "    qualification = entry.get(\"qualification\", \"\")\n",
    "    area = entry.get(\"area\", \"\")\n",
    "    district = entry.get(\"district\", \"\")\n",
    "    state = entry.get(\"state\", \"\")\n",
    "    occupation = entry.get(\"occupation\", \"\")\n",
    "    prompt = entry.get(\"prompt\", \"\")\n",
    "    audio_segmented_duration = entry.get(\"audio_segmented_duration\", 0)\n",
    "    \n",
    "    # Process verbatim text\n",
    "    for verb in entry.get(\"verbatim\", []):\n",
    "        text = verb.get(\"text\", \"\")\n",
    "        speaker_id = verb.get(\"speaker_id\", \"\")\n",
    "        records.append({\n",
    "            \"language\": language,\n",
    "            \"audio_duration\": audio_duration,\n",
    "            \"scenario\": scenario,\n",
    "            \"task_name\": task_name,\n",
    "            \"gender\": gender,\n",
    "            \"age_group\": age_group,\n",
    "            \"job_type\": job_type,\n",
    "            \"qualification\": qualification,\n",
    "            \"area\": area,\n",
    "            \"district\": district,\n",
    "            \"state\": state,\n",
    "            \"occupation\": occupation,\n",
    "            \"prompt\": prompt,\n",
    "            \"audio_segmented_duration\": audio_segmented_duration,\n",
    "            \"text\": text,\n",
    "            \"speaker_id\": speaker_id\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Remove empty entries (if any)\n",
    "    df = df[df['text'].str.strip() != \"\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory_path):\n",
    "    \"\"\"Process all JSON files in the specified directory.\"\"\"\n",
    "    all_records = []\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    transcript_data = json.load(file)\n",
    "                    df = process_transcript_data(transcript_data)\n",
    "                    df['audio_file'] = \"Punjabi/rv1b/train/\"+filename[:-4]+'wav'\n",
    "                    all_records.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "                break\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    if all_records:\n",
    "        combined_df = pd.concat(all_records, ignore_index=True)\n",
    "    else:\n",
    "        combined_df = pd.DataFrame()  # Empty DataFrame if no records\n",
    "\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>audio_duration</th>\n",
       "      <th>scenario</th>\n",
       "      <th>task_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_group</th>\n",
       "      <th>job_type</th>\n",
       "      <th>qualification</th>\n",
       "      <th>area</th>\n",
       "      <th>district</th>\n",
       "      <th>state</th>\n",
       "      <th>occupation</th>\n",
       "      <th>prompt</th>\n",
       "      <th>audio_segmented_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Punjabi</td>\n",
       "      <td>35.124</td>\n",
       "      <td>Extempore</td>\n",
       "      <td>Language Specific</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Student</td>\n",
       "      <td>Upto 12th</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rupnagar</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Student</td>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਤੁਹਾਡੇ ਰਾਜ ਦੀਆਂ ਖੇਤਰੀ ਉਪਭਾਸ਼ਾਵਾਂ ...</td>\n",
       "      <td>35.094</td>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਾਡੇ ਰਾਜ ਦੀਆਂ ਵੱਖ ਵੱਖ ਖੇਤਰੀ ਉਪ ਭਾਸ਼...</td>\n",
       "      <td>0</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580801528.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Punjabi</td>\n",
       "      <td>46.973</td>\n",
       "      <td>Read</td>\n",
       "      <td>Digital Payment Commands</td>\n",
       "      <td>Male</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>Undergrad and Grad.</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rupnagar</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Housekeeping</td>\n",
       "      <td>ਕੀ ਤੁਸੀਂ ਦੇਖ ਸਕਦੇ ਹੋ ਕਿ ਕੀ ਇਸ ਮਹੀਨੇ ਦੀ ਤਨਖਾਹ ਮ...</td>\n",
       "      <td>46.050</td>\n",
       "      <td>ਕੀ ਤੁਸੀਂ ਦੇਖ ਸਕਦੇ ਹੋ ਕਿ ਕਿਉਂ ਇਸ ਮਹੀਨੇ ਦੀ ਤਨਖਾਹ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580802376.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punjabi</td>\n",
       "      <td>68.520</td>\n",
       "      <td>Extempore</td>\n",
       "      <td>Language Specific</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Student</td>\n",
       "      <td>Upto 12th</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Rupnagar</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Student</td>\n",
       "      <td>ਆਪਣੇ ਇਤਿਹਾਸ ਦੌਰਾਨ ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਹੋਰ ਭਾਸ਼ਾਵਾਂ ਅਤ...</td>\n",
       "      <td>66.764</td>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਗੱਲ ਕਰਨ ਦਾ ਇੱਕ ਸਭ ਤੋਂ ਸੌਖਾ ਸਾਧਨ ਮ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580803154.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Punjabi</td>\n",
       "      <td>68.520</td>\n",
       "      <td>Extempore</td>\n",
       "      <td>Language Specific</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Student</td>\n",
       "      <td>Upto 12th</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Rupnagar</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Student</td>\n",
       "      <td>ਆਪਣੇ ਇਤਿਹਾਸ ਦੌਰਾਨ ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਹੋਰ ਭਾਸ਼ਾਵਾਂ ਅਤ...</td>\n",
       "      <td>66.764</td>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਭ ਤੋਂ ਜ਼ਿਆਦਾ ਸੌਖੀ ਮੰਨੀ ਜਾਂਦੀ ਹੈ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580803154.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Punjabi</td>\n",
       "      <td>68.520</td>\n",
       "      <td>Extempore</td>\n",
       "      <td>Language Specific</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-30</td>\n",
       "      <td>Student</td>\n",
       "      <td>Upto 12th</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Rupnagar</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Student</td>\n",
       "      <td>ਆਪਣੇ ਇਤਿਹਾਸ ਦੌਰਾਨ ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਹੋਰ ਭਾਸ਼ਾਵਾਂ ਅਤ...</td>\n",
       "      <td>66.764</td>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਇਹੋ ਜਿਹੀ ਭਾਸ਼ਾ ਹੈ ਜਿਵੇਂ ਨੋਰਮਲ ਕੋਈ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580803154.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  audio_duration   scenario                 task_name  gender  \\\n",
       "0  Punjabi          35.124  Extempore         Language Specific  Female   \n",
       "1  Punjabi          46.973       Read  Digital Payment Commands    Male   \n",
       "2  Punjabi          68.520  Extempore         Language Specific  Female   \n",
       "3  Punjabi          68.520  Extempore         Language Specific  Female   \n",
       "4  Punjabi          68.520  Extempore         Language Specific  Female   \n",
       "\n",
       "  age_group     job_type        qualification   area  district   state  \\\n",
       "0     18-30      Student            Upto 12th  Rural  Rupnagar  Punjab   \n",
       "1     18-30  Blue Collar  Undergrad and Grad.  Rural  Rupnagar  Punjab   \n",
       "2     18-30      Student            Upto 12th  Urban  Rupnagar  Punjab   \n",
       "3     18-30      Student            Upto 12th  Urban  Rupnagar  Punjab   \n",
       "4     18-30      Student            Upto 12th  Urban  Rupnagar  Punjab   \n",
       "\n",
       "     occupation                                             prompt  \\\n",
       "0       Student  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਤੁਹਾਡੇ ਰਾਜ ਦੀਆਂ ਖੇਤਰੀ ਉਪਭਾਸ਼ਾਵਾਂ ...   \n",
       "1  Housekeeping  ਕੀ ਤੁਸੀਂ ਦੇਖ ਸਕਦੇ ਹੋ ਕਿ ਕੀ ਇਸ ਮਹੀਨੇ ਦੀ ਤਨਖਾਹ ਮ...   \n",
       "2       Student  ਆਪਣੇ ਇਤਿਹਾਸ ਦੌਰਾਨ ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਹੋਰ ਭਾਸ਼ਾਵਾਂ ਅਤ...   \n",
       "3       Student  ਆਪਣੇ ਇਤਿਹਾਸ ਦੌਰਾਨ ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਹੋਰ ਭਾਸ਼ਾਵਾਂ ਅਤ...   \n",
       "4       Student  ਆਪਣੇ ਇਤਿਹਾਸ ਦੌਰਾਨ ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਹੋਰ ਭਾਸ਼ਾਵਾਂ ਅਤ...   \n",
       "\n",
       "   audio_segmented_duration  \\\n",
       "0                    35.094   \n",
       "1                    46.050   \n",
       "2                    66.764   \n",
       "3                    66.764   \n",
       "4                    66.764   \n",
       "\n",
       "                                                text  speaker_id  \\\n",
       "0  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਾਡੇ ਰਾਜ ਦੀਆਂ ਵੱਖ ਵੱਖ ਖੇਤਰੀ ਉਪ ਭਾਸ਼...           0   \n",
       "1  ਕੀ ਤੁਸੀਂ ਦੇਖ ਸਕਦੇ ਹੋ ਕਿ ਕਿਉਂ ਇਸ ਮਹੀਨੇ ਦੀ ਤਨਖਾਹ...           0   \n",
       "2  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਗੱਲ ਕਰਨ ਦਾ ਇੱਕ ਸਭ ਤੋਂ ਸੌਖਾ ਸਾਧਨ ਮ...           0   \n",
       "3  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਭ ਤੋਂ ਜ਼ਿਆਦਾ ਸੌਖੀ ਮੰਨੀ ਜਾਂਦੀ ਹੈ ...           0   \n",
       "4  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਇਹੋ ਜਿਹੀ ਭਾਸ਼ਾ ਹੈ ਜਿਵੇਂ ਨੋਰਮਲ ਕੋਈ...           0   \n",
       "\n",
       "                                audio_file  \n",
       "0  Punjabi/rv1b/train/5066549580801528.wav  \n",
       "1  Punjabi/rv1b/train/5066549580802376.wav  \n",
       "2  Punjabi/rv1b/train/5066549580803154.wav  \n",
       "3  Punjabi/rv1b/train/5066549580803154.wav  \n",
       "4  Punjabi/rv1b/train/5066549580803154.wav  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = \"Punjabi\\/rv1b\\/train\"\n",
    "combined_df = process_directory(directory_path)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'audio_duration', 'scenario', 'task_name', 'gender',\n",
       "       'age_group', 'job_type', 'qualification', 'area', 'district', 'state',\n",
       "       'occupation', 'prompt', 'audio_segmented_duration', 'text',\n",
       "       'speaker_id', 'audio_file'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਾਡੇ ਰਾਜ ਦੀਆਂ ਵੱਖ ਵੱਖ ਖੇਤਰੀ ਉਪ ਭਾਸ਼...</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580801528.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ਕੀ ਤੁਸੀਂ ਦੇਖ ਸਕਦੇ ਹੋ ਕਿ ਕਿਉਂ ਇਸ ਮਹੀਨੇ ਦੀ ਤਨਖਾਹ...</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580802376.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਗੱਲ ਕਰਨ ਦਾ ਇੱਕ ਸਭ ਤੋਂ ਸੌਖਾ ਸਾਧਨ ਮ...</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580803154.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਭ ਤੋਂ ਜ਼ਿਆਦਾ ਸੌਖੀ ਮੰਨੀ ਜਾਂਦੀ ਹੈ ...</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580803154.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਇਹੋ ਜਿਹੀ ਭਾਸ਼ਾ ਹੈ ਜਿਵੇਂ ਨੋਰਮਲ ਕੋਈ...</td>\n",
       "      <td>Punjabi/rv1b/train/5066549580803154.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਾਡੇ ਰਾਜ ਦੀਆਂ ਵੱਖ ਵੱਖ ਖੇਤਰੀ ਉਪ ਭਾਸ਼...   \n",
       "1  ਕੀ ਤੁਸੀਂ ਦੇਖ ਸਕਦੇ ਹੋ ਕਿ ਕਿਉਂ ਇਸ ਮਹੀਨੇ ਦੀ ਤਨਖਾਹ...   \n",
       "2  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਗੱਲ ਕਰਨ ਦਾ ਇੱਕ ਸਭ ਤੋਂ ਸੌਖਾ ਸਾਧਨ ਮ...   \n",
       "3  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਸਭ ਤੋਂ ਜ਼ਿਆਦਾ ਸੌਖੀ ਮੰਨੀ ਜਾਂਦੀ ਹੈ ...   \n",
       "4  ਪੰਜਾਬੀ ਭਾਸ਼ਾ ਇਹੋ ਜਿਹੀ ਭਾਸ਼ਾ ਹੈ ਜਿਵੇਂ ਨੋਰਮਲ ਕੋਈ...   \n",
       "\n",
       "                                audio_file  \n",
       "0  Punjabi/rv1b/train/5066549580801528.wav  \n",
       "1  Punjabi/rv1b/train/5066549580802376.wav  \n",
       "2  Punjabi/rv1b/train/5066549580803154.wav  \n",
       "3  Punjabi/rv1b/train/5066549580803154.wav  \n",
       "4  Punjabi/rv1b/train/5066549580803154.wav  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vits_df = combined_df[['text', 'audio_file']]\n",
    "vits_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vits_df = vits_df.dropna(subset=['text', 'audio_file'])\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'[^ਅ-ਹੳ-ੴ੦-੯\\s.,!?\\'\"()\\-]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "vits_df['text'] = vits_df['text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_audio_file(file_path):\n",
    "    return os.path.isfile(file_path)\n",
    "\n",
    "\n",
    "vits_df = vits_df[vits_df['audio_file'].apply(validate_audio_file)]\n",
    "vits_df['audio_file'] = vits_df['audio_file'].apply(lambda x: os.path.abspath(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ਪਜਬ ਭਸ਼ ਸਡ ਰਜ ਦਆ ਵਖ ਵਖ ਖਤਰ ਉਪ ਭਸ਼ ਤ ਬਹਤ ਹ ਵਖਰ ਹ ...</td>\n",
       "      <td>c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ਕ ਤਸ ਦਖ ਸਕਦ ਹ ਕ ਕਉ ਇਸ ਮਹਨ ਦ ਤਨਖਹ ਮਰ ਤਮਲਨਡ ਮਰਕ ...</td>\n",
       "      <td>c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ਪਜਬ ਭਸ ਗਲ ਕਰਨ ਦ ਇਕ ਸਭ ਤ ਸਖ ਸਧਨ ਮਨ ਜਦ ਹ ਜਨ ਵ ਸਡ...</td>\n",
       "      <td>c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ਪਜਬ ਭਸ ਸਭ ਤ ਜਆਦ ਸਖ ਮਨ ਜਦ ਹ ਤ ਜਹ ਵਪਰ ਅਤ ਹਰ ਵ ਛਤ...</td>\n",
       "      <td>c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ਪਜਬ ਭਸ ਇਹ ਜਹ ਭਸ ਹ ਜਵ ਨਰਮਲ ਕਈ ਵ ਇਨਸਨ ਹ ਉਹ ਆਰਮ ਨ...</td>\n",
       "      <td>c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ਪਜਬ ਭਸ਼ ਸਡ ਰਜ ਦਆ ਵਖ ਵਖ ਖਤਰ ਉਪ ਭਸ਼ ਤ ਬਹਤ ਹ ਵਖਰ ਹ ...   \n",
       "1  ਕ ਤਸ ਦਖ ਸਕਦ ਹ ਕ ਕਉ ਇਸ ਮਹਨ ਦ ਤਨਖਹ ਮਰ ਤਮਲਨਡ ਮਰਕ ...   \n",
       "2  ਪਜਬ ਭਸ ਗਲ ਕਰਨ ਦ ਇਕ ਸਭ ਤ ਸਖ ਸਧਨ ਮਨ ਜਦ ਹ ਜਨ ਵ ਸਡ...   \n",
       "3  ਪਜਬ ਭਸ ਸਭ ਤ ਜਆਦ ਸਖ ਮਨ ਜਦ ਹ ਤ ਜਹ ਵਪਰ ਅਤ ਹਰ ਵ ਛਤ...   \n",
       "4  ਪਜਬ ਭਸ ਇਹ ਜਹ ਭਸ ਹ ਜਵ ਨਰਮਲ ਕਈ ਵ ਇਨਸਨ ਹ ਉਹ ਆਰਮ ਨ...   \n",
       "\n",
       "                                          audio_file  \n",
       "0  c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...  \n",
       "1  c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...  \n",
       "2  c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...  \n",
       "3  c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...  \n",
       "4  c:\\Users\\prash\\Downloads\\ai_speech_project\\Pun...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vits_df['audio_file'] = vits_df['audio_file'].apply(lambda x: os.path.abspath(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vits_df.fillna({'text': ''}, inplace=True)\n",
    "train_df, temp_df = train_test_split(vits_df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('vits_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./custom_audio_text_train_filelist.txt', 'w', encoding='utf-8') as train_filelist:\n",
    "    for index, row in train_df.iterrows():\n",
    "        train_filelist.write(f\"{os.path.basename(row['audio_file'])[:-4]}|{row['text']}\\n\")\n",
    "\n",
    "# Write validation file list\n",
    "with open('./custom_audio_text_val_filelist.txt', 'w', encoding='utf-8') as val_filelist:\n",
    "    for index, row in val_df.iterrows():\n",
    "        val_filelist.write(f\"{os.path.basename(row['audio_file'])[:-4]}|{row['text']}\\n\")\n",
    "\n",
    "# Write test file list\n",
    "with open('./custom_audio_text_test_filelist.txt', 'w', encoding='utf-8') as test_filelist:\n",
    "    for index, row in test_df.iterrows():\n",
    "        test_filelist.write(f\"{os.path.basename(row['audio_file'])[:-4]}|{row['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
